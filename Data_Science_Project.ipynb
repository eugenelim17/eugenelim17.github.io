{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eugenelim17/eugenelim17.github.io/blob/main/Data_Science_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Introduction:** The team members, Eugene Lim and Tyler Simms, will be using a dataset on 2023 LinkedIn Job Post Listings over a two day period during the year to identify trends within the current US job market, specifically for remote occupations and non-remote occupations. Our working project title is \"Trends, Patterns, and Directions in the 2023 U.S. job market\". We will be working with this dataset because it provides great detail, and several datas we could use such as the type of job, pay period, salary, company IDs, and whether remote work is allowed or not.\n",
        "\n",
        "Link to dataset: https://www.kaggle.com/datasets/arshkon/linkedin-job-postings\n",
        "\n",
        "Link to GitHub repo: https://github.com/eugenelim17/eugenelim17.github.io/tree/main\n",
        "\n",
        "Link to Trello Board: https://trello.com/b/nKeaOhI6/data-science-job-market-project"
      ],
      "metadata": {
        "id": "Wnywg8jhC2cw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Collaboration Plan:** We plan to meet once a week through Zoom in order to work on the project. Alternative ways that we will use to communicate will be via text message, and also on a Trello dashboard where we will be uploading any important updates, questions, and idea proposals that we may have. We have also created a Github repo that is shared with each other in order to organize, update and maintain our code in order with each other. We will be collaborating on the code in our notebook file through Google Colab."
      ],
      "metadata": {
        "id": "o6miIG-UC-Aj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "8A-OYWIggjVB",
        "outputId": "89c29f6e-d100-4e23-9978-5386145c23cb"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-1220111b-9863-4a6b-b9aa-a3d831640349\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-1220111b-9863-4a6b-b9aa-a3d831640349\">\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "csv_file_path = '/content/job_postings.csv'\n",
        "job_postings_df = pd.read_csv(csv_file_path)\n"
      ],
      "metadata": {
        "id": "PA0cPKP5ip04"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Project Plan:** As mentioned above, our dataset includes a high volune of observations on individual LinkedIn job post listings that appeaared on the LinkedIn website over a two day period in 2023. Our team has chosen this dataset because the dataset is quite robust and the creater did significant due dilligence in gathering the data for each observation. Our first question we hope to answer is the how the relationship appears between jobs that are in person and remote. The dataset contains a variable that already categorizes each job as in person or remote. Through filtering on this variable, we can find material and interesting differences based on relevant variables. Our second question, or really set of questions, includes those such as \"What industries have the highest and lowest salaries and benefits?\", \"What are most lucrative individual job titles regardless of industry?\", and \"Which geographic job locations, states and cities, have the highest and lowest salaries and benefits?\""
      ],
      "metadata": {
        "id": "EOxtl1irTCzU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "job_postings_df.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uT-bElolky2Q",
        "outputId": "28eeb174-39d9-4309-a619-4664e03a89ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "job_id                          int64\n",
              "company_id                    float64\n",
              "title                          object\n",
              "description                    object\n",
              "max_salary                    float64\n",
              "med_salary                    float64\n",
              "min_salary                    float64\n",
              "pay_period                     object\n",
              "formatted_work_type            object\n",
              "location                       object\n",
              "applies                       float64\n",
              "original_listed_time          float64\n",
              "remote_allowed                float64\n",
              "views                         float64\n",
              "job_posting_url                object\n",
              "application_url                object\n",
              "application_type               object\n",
              "expiry                        float64\n",
              "closed_time                   float64\n",
              "formatted_experience_level     object\n",
              "skills_desc                    object\n",
              "listed_time                   float64\n",
              "posting_domain                 object\n",
              "sponsored                       int64\n",
              "work_type                      object\n",
              "currency                       object\n",
              "compensation_type              object\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "job_postings_df.job_id = job_postings_df.job_id.astype(str)\n",
        "job_postings_df.company_id = job_postings_df.company_id.astype(str)"
      ],
      "metadata": {
        "id": "ss0kn-mGTydg"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "job_postings_df.dtypes"
      ],
      "metadata": {
        "id": "yrcJ_lxIT00n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Listed above are the variables we will be using, and their dataypes."
      ],
      "metadata": {
        "id": "ShvgvzYIk1SO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "job_postings_df = job_postings_df[job_postings_df['compensation_type'].notna()]\n",
        "#Rows that do not have a compensation type are removed here using .notna()\n",
        "job_postings_df['med_salary'].replace('', np.nan, inplace=True)\n",
        "job_postings_df = job_postings_df.dropna(subset=['med_salary'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQDMHqueNm3W",
        "outputId": "933c173e-4229-45c1-ee08-308c0720b573"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-70-0d1d53ede5dc>:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  job_postings_df['med_salary'].replace('', np.nan, inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our first step of the coding portion of the project was to ensure that all the job post observations we were using had a compensation value included. When looking at the dataset, we have noticed that there were many job postings that did not include a compensation value. So, in order to get rid of these rows without a compensation type, we've added a .na() function. This is also done with med_salary, for the same reason of eliminating any rows of data without a median salary provided."
      ],
      "metadata": {
        "id": "5ozS0ZxRNnic"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Any salary that is based off of an hourly basis is adjusted to a yearly salary, by multiplying by 40 since that is the American national standard for weekly hours worked.\n",
        "job_postings_df['max_salary'] = job_postings_df.apply(lambda row: row['max_salary'] * 40 * 52 if row['pay_period'] == 'Hourly' else row['max_salary'], axis=1)\n",
        "job_postings_df['med_salary'] = job_postings_df.apply(lambda row: row['med_salary'] * 40 * 52 if row['pay_period'] == 'Hourly' else row['med_salary'], axis=1)\n",
        "job_postings_df['min_salary'] = job_postings_df.apply(lambda row: row['min_salary'] * 40 * 52 if row['pay_period'] == 'Hourly' else row['min_salary'], axis=1)\n",
        "job_postings_df['pay_period'] = 'Yearly'  # Update the pay period to 'Yearly'"
      ],
      "metadata": {
        "id": "cKlH-q_YNtOJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After removing the rows with no compensation type, we see that there are two types of compensation wages left: hourly, and yearly. It is much more organized to keep just one unit for the salary, so we used yearly. This is done by multiplying any salary that has an hourly wage by 40 since that is the American standard of hours worked per week, and then multiplied by 52 since there are 52 weeks in a year."
      ],
      "metadata": {
        "id": "rqY7BxGjNt3o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Fill non-remote workers with a value of 0\n",
        "job_postings_df['remote_allowed'] = job_postings_df['remote_allowed'].fillna(0)\n",
        "\n",
        "#Calculate summary statistics for remote and non-remote workers based on yearly median salary\n",
        "remote_workers = job_postings_df[job_postings_df['remote_allowed'] == 1]\n",
        "non_remote_workers = job_postings_df[job_postings_df['remote_allowed'] == 0]"
      ],
      "metadata": {
        "id": "umuj-gliNyP9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the dataframe, we see that remote workers are labelled '1' if they are remote in the 'remote_allowed' variable, but if they are in person then they do not have a variable. We labelled these in-person workers as '0' by simply using the .fillna(0) function."
      ],
      "metadata": {
        "id": "w51cRq4cNy8G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Summary statistics for remote workers\n",
        "summary_remote = remote_workers['med_salary'].describe()\n",
        "\n",
        "# Summary statistics for non-remote workers\n",
        "summary_non_remote = non_remote_workers['med_salary'].describe()\n",
        "\n",
        "# Print the summary statistics\n",
        "print(\"Summary Statistics for Remote Workers:\")\n",
        "print(summary_remote)\n",
        "\n",
        "print(\"\\nSummary Statistics for Non-Remote Workers:\")\n",
        "print(summary_non_remote)"
      ],
      "metadata": {
        "id": "uvePBsgGN4fS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "When comparing the two types of workers by their summary statistics, we can see that the remote workers have a significantly higher average median salary (93,813.64 USD) compared to non-remote workers (34,038.52 USD). Both categories also have relatively high standard deviations, which indicates a wide of variation in salaries, but remote workers have a higher standard deviation. We can already predict both will be skewed right in a graph, since the means for both types of workers are greater than their medians, which are seen from the 50th percentile."
      ],
      "metadata": {
        "id": "dZxJzKMeN6KY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "job_postings_df['med_salary'].plot.hist(bins=50, color='blue', alpha=0.7, edgecolor='black', title='Distribution of Median Yearly Salaries')\n",
        "plt.xlabel('Median Yearly Salary')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3OPPQzHIN9Ap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Attached above is a histogram which shows the distribution of median yearly salaries. It is orginally skewed heavily to the right, and this is because a vast majority of salaries are less than the 100,000 range, with far outliers reaching $1 million."
      ],
      "metadata": {
        "id": "WXMNHk6iOFUj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "job_postings_df['med_salary'] = np.log1p(job_postings_df['med_salary'])\n",
        "job_postings_df['med_salary'].plot.hist(bins=50, color='blue', alpha=0.7, edgecolor='black', title='Distribution of Median Yearly Salaries (Log-Transformed)')\n",
        "\n",
        "# Set labels and title\n",
        "plt.xlabel('Log(Median Yearly Salary)')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kg1OcMsAOIsC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To fix the skew we have applied a logarithmic transformation, specifically by taking in the logarithmic value each of the median salaries, which fixes the skew much better makes the histogram look much more symmetrical."
      ],
      "metadata": {
        "id": "2eoJWL8vOh-C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "job_postings_df = job_postings_df.dropna(subset=['compensation_type', 'med_salary'])\n",
        "job_postings_df.title.value_counts().head(200).to_frame()"
      ],
      "metadata": {
        "id": "AbJWjhq9OkSf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the mapping from job titles to industries\n",
        "job_title_to_industry_mapping = {\n",
        "    \"Warehouse Order Selector\": \"Warehouse\",\n",
        "    \"Package Handler (Warehouse like)\": \"Warehouse\",\n",
        "    \"Warehouse Associate\": \"Warehouse\",\n",
        "    \"Warehouse Worker - SAS Safety Corp.\": \"Warehouse\",\n",
        "    \"Equipment Technician\": \"Technician\",\n",
        "    \"Field Service Technician\": \"Technician\",\n",
        "    \"Pest Control Technician\": \"Technician\",\n",
        "    \"Central Services Technician\": \"Technician\"\n",
        "}\n",
        "\n",
        "# Use the .replace() method to create the 'industries' column\n",
        "job_postings_df['industries'] = job_postings_df['title'].replace(job_title_to_industry_mapping)"
      ],
      "metadata": {
        "id": "ME9GJ_RSOnVa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here a map called 'Industries' is created, where eight occupations are organized into a dictionary based on what type of job they are, and the two types in this example are 'Warehouse' and 'Technician'."
      ],
      "metadata": {
        "id": "S7rS2N11O0t3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "selected_industries = [\"Warehouse\", \"Technician\"]\n",
        "filtered_df = job_postings_df[job_postings_df['industries'].isin(selected_industries)].copy()\n",
        "\n",
        "# Converted the logarithmic values back to their actual yearly salaries using np.exp\n",
        "filtered_df['med_salary'] = np.exp(filtered_df['med_salary'])\n",
        "\n",
        "# Summary statistics for \"med_salary\" for each industry\n",
        "summary_statistics = filtered_df.groupby('industries')['med_salary'].describe()\n",
        "\n",
        "# Print the summary statistics\n",
        "print(summary_statistics)\n"
      ],
      "metadata": {
        "id": "8UPz6NjjO6tV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We create the summary statistics between technicians and warehouse workers, and the first thing to do is to revert the salaries back to their original values from the logarithmic values, by using the np.exp() function. As seen from the summary statistic, we can see the \"Technician\" industry generally offers higher median salaries, with an average around 21,378 USD, but with significant variation, which is evidenced by the high standard deviation. The \"Warehouse\" industry has a lower average median salary of around 8,391 USD, and has a lower, but still considerable variation in salary. In both industries, there is a wide range of median salaries, with the maximum salaries being significantly higher than the average. This suggests that some job postings within these industries offer very high salaries, while others offer lower salaries."
      ],
      "metadata": {
        "id": "_S-W0t9lPBWs"
      }
    }
  ]
}
